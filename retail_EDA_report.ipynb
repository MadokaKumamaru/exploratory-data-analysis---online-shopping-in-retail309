{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from scipy import stats\n",
    "from scipy.stats import yeojohnson\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from RDS database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which loads the yaml credentials file and return \n",
    "# the data dictionary contained within\n",
    "def import_yaml():\n",
    "    with open('credentials.yaml', 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "yaml_dictionary = import_yaml() \n",
    "\n",
    "# Create a class which contains methods we will use to \n",
    "# extract data from the RDS database\n",
    "class RDSDatabaseConnector:\n",
    "    def __init__(self, yaml_dictionary):\n",
    "        self.yaml_dictionary = yaml_dictionary\n",
    "        \n",
    "    # Define a method which initialises a SQLAlchemy engine \n",
    "    # from the credentials provided to the class\n",
    "    def connect_database(self):\n",
    "        DATABASE_TYPE = 'postgresql'\n",
    "        DBAPI = 'psycopg2'\n",
    "        ENDPOINT = self.yaml_dictionary['RDS_HOST']\n",
    "        USER = self.yaml_dictionary['RDS_USER']\n",
    "        PASSWORD = self.yaml_dictionary['RDS_PASSWORD']\n",
    "        PORT = self.yaml_dictionary['RDS_PORT']\n",
    "        DATABASE = self.yaml_dictionary['RDS_DATABASE']\n",
    "        return create_engine(f'{DATABASE_TYPE}+{DBAPI}://{USER}:{PASSWORD}@{ENDPOINT}:{PORT}/{DATABASE}')\n",
    "            \n",
    "    # Define a method which extracts data from the RDS \n",
    "    # database and returns it as a Pandas DataFrame\n",
    "    def extract_data(self, engine):\n",
    "        return pd.read_sql_table('customer_activity', engine)\n",
    "    \n",
    "# Use the methods to extract data\n",
    "customer_activity_class = RDSDatabaseConnector(yaml_dictionary)\n",
    "engine = customer_activity_class.connect_database()\n",
    "customer_activity = customer_activity_class.extract_data(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types before the transformation:\n",
      "administrative              category\n",
      "administrative_duration      float64\n",
      "informational               category\n",
      "informational_duration       float64\n",
      "product_related             category\n",
      "product_related_duration     float64\n",
      "bounce_rates                 float64\n",
      "exit_rates                   float64\n",
      "page_values                  float64\n",
      "month                       category\n",
      "operating_systems           category\n",
      "browser                     category\n",
      "region                      category\n",
      "traffic_type                category\n",
      "visitor_type                category\n",
      "weekend                         bool\n",
      "revenue                         bool\n",
      "dtype: object\n",
      "Data types after the transformation:\n",
      "administrative              category\n",
      "administrative_duration      float64\n",
      "informational               category\n",
      "informational_duration       float64\n",
      "product_related             category\n",
      "product_related_duration     float64\n",
      "bounce_rates                 float64\n",
      "exit_rates                   float64\n",
      "page_values                  float64\n",
      "month                       category\n",
      "operating_systems           category\n",
      "browser                     category\n",
      "region                      category\n",
      "traffic_type                category\n",
      "visitor_type                category\n",
      "weekend                         bool\n",
      "revenue                         bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get the data type for each column\n",
    "print('Data types before the transformation:')\n",
    "print(customer_activity.dtypes)\n",
    "# Create a class which contains methods that can be appplied\n",
    "# to the columns to handle data type conversions\n",
    "class ColumnTransform:\n",
    "    def __init__(self, dataframe): \n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "    # Define a method which converts columns to category datatype\n",
    "    def convert_to_category(self, column):\n",
    "        self.dataframe[column] = self.dataframe[column].astype('category')\n",
    "         \n",
    "\n",
    "# Covert data types for some columns to category \n",
    "customer_activity_DataTransform = ColumnTransform(customer_activity)\n",
    "columns_to_transform = ['administrative', 'product_related', 'informational', \n",
    "                        'month', 'operating_systems', 'browser', 'region', \n",
    "                        'traffic_type', 'visitor_type']\n",
    "for column in columns_to_transform:\n",
    "    customer_activity_DataTransform.convert_to_category(column)\n",
    "    \n",
    "# Check if the columns have been transformed correctly    \n",
    "print('Data types after the transformation:')\n",
    "print(customer_activity.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following columns have been converted to category data type:\n",
    "- administrative\n",
    "- informational\n",
    "- product_related\n",
    "- month\n",
    "- operating_systems\n",
    "- browser\n",
    "- region\n",
    "- traffic_type\n",
    "- visitor_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class which contains methods to extract information from the DataFrame and its columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class which contains methods to extract information\n",
    "# from the DataFrame and its columns\n",
    "class DataFrameInfo:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "    # Define a method to describe all columns in the DataFrame\n",
    "    def get_description(self):\n",
    "        print('Description for columns:')\n",
    "        print(self.dataframe.describe())\n",
    "        \n",
    "    # Define a method to extract statistical values (mean, median\n",
    "    # and standard deviation) from the float64 columns\n",
    "    def get_statistical_values(self, column):\n",
    "        print(f'Mean for {column}:', self.dataframe[column].mean())\n",
    "        print(f'Median for {column}:', self.dataframe[column].median())\n",
    "        print(f'Standard Deviation for {column}:', self.dataframe[column].std())\n",
    "        \n",
    "    # Define a method to count distinct values in categorical columns\n",
    "    def get_counts(self, column):\n",
    "        self.dataframe[column].value_counts()\n",
    "        \n",
    "    # Define a method to print out the shape of the DataFrame\n",
    "    def get_shape(self):\n",
    "        print('Shape of the DataFrame:', self.dataframe.shape)\n",
    "        \n",
    "    # Define a method to generate a count and percentage of NULL values \n",
    "    # in each column\n",
    "    def get_NULL_counts(self, column):\n",
    "        print(f'Number of NULLs for {column}:', self.dataframe[column].isnull().sum())\n",
    "        print(f'Percentage of NULLs for {column}:', round(self.dataframe[column].isnull().sum()/\n",
    "              len(self.dataframe) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class to visualise insights from the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    # Define a method to plot histogram to check skewness\n",
    "    def plot_histograms(self, column):\n",
    "        self.dataframe[column].hist(bins = 3)\n",
    "        plt.title(f'Histogram for {column}')\n",
    "        plt.show()\n",
    "        \n",
    "    # Define a method to plot Q-Q plot to check skewness\n",
    "    def plot_qqplot(self, column):\n",
    "        qqplot(self.dataframe[column], scale = 1, line = 'q', fit = True)\n",
    "        plt.title(f'Q-Q plot for {column}')\n",
    "        plt.show()\n",
    "        \n",
    "    # Define a method to plot box plot to check outliers\n",
    "    def plot_boxplot(self, column):\n",
    "        sns.boxplot(y = self.dataframe[column], color = 'lightgreen', showfliers = True)\n",
    "        plt.title(f'Box plot with scatter points of {column}')\n",
    "        plt.show()\n",
    "        \n",
    "    # Define a method to plot correlation matrix\n",
    "    def plot_correlation_matrix(self):\n",
    "        sns.heatmap(self.dataframe.corr(), annot = True, cmap = 'coolwarm')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class to perform EDA transformations on the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameTransform:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "    # Define a method to impute NULLs with mode\n",
    "    def mode_impute(self, column):\n",
    "        column_mode = self.dataframe[column].mode().iloc[0]\n",
    "        self.dataframe[column].fillna(column_mode, inplace=True)\n",
    "        \n",
    "    # Define a method to impute NULLs with mean\n",
    "    def mean_impute(self, column):\n",
    "        self.dataframe[column] = self.dataframe[column].fillna(self.dataframe[column].mean())\n",
    "        \n",
    "    # Define a method to impute NULLs with median\n",
    "    def median_impute(self, column):\n",
    "        self.dataframe[column] = self.dataframe[column].fillna(self.dataframe[column].median())\n",
    "        \n",
    "    # Define a method to compute log transform\n",
    "    def log_transform(self, column):\n",
    "        self.dataframe[column] = self.dataframe[column].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "        \n",
    "    # Define a method to compute Yeo-Johnson transform\n",
    "    def yeo_johnson_transform(self, column):\n",
    "        self.dataframe[column] = stats.yeojohnson(self.dataframe[column])[0]\n",
    "        \n",
    "    # Define a method to drop outliers\n",
    "    def drop_outliers(self, column):\n",
    "        Q1 = self.dataframe[column].quantile(0.25)\n",
    "        Q3 = self.dataframe[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        outliers = self.dataframe[(self.dataframe[column] >= Q1 - 1.5*IQR) & (self.dataframe[column] <= Q3 + 1.5*IQR)]\n",
    "        self.dataframe = self.dataframe.drop(outliers.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put columns into different groups based on data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = customer_activity.columns\n",
    "numeric_columns = ['administrative_duration', 'informational_duration', 'product_related_duration',\n",
    "                   'bounce_rates', 'exit_rates', 'page_values']\n",
    "categorical_columns = ['administrative', 'informational', 'product_related', 'month',\n",
    "                       'operating_systems', 'browser', 'region', 'visitor_type']\n",
    "boolean_columns = ['weekend', 'revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create instances of the classes:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
